[
    {
        "loss": 0.9945,
        "grad_norm": 0.002670028479769826,
        "learning_rate": 9.928622412562456e-05,
        "epoch": 0.02
    },
    {
        "loss": 1.1044,
        "grad_norm": 0.00800681859254837,
        "learning_rate": 9.857244825124911e-05,
        "epoch": 0.04
    },
    {
        "loss": 1.0259,
        "grad_norm": 0.017408117651939392,
        "learning_rate": 9.785867237687366e-05,
        "epoch": 0.06
    },
    {
        "loss": 1.0268,
        "grad_norm": 0.04127740487456322,
        "learning_rate": 9.714489650249822e-05,
        "epoch": 0.09
    },
    {
        "loss": 1.0382,
        "grad_norm": 0.07124276459217072,
        "learning_rate": 9.643112062812278e-05,
        "epoch": 0.11
    },
    {
        "loss": 1.0435,
        "grad_norm": 0.07644373178482056,
        "learning_rate": 9.571734475374732e-05,
        "epoch": 0.13
    },
    {
        "loss": 1.0433,
        "grad_norm": 0.1729957014322281,
        "learning_rate": 9.500356887937188e-05,
        "epoch": 0.15
    },
    {
        "loss": 0.9956,
        "grad_norm": 0.15276560187339783,
        "learning_rate": 9.428979300499644e-05,
        "epoch": 0.17
    },
    {
        "loss": 0.9981,
        "grad_norm": 0.2952185571193695,
        "learning_rate": 9.357601713062099e-05,
        "epoch": 0.19
    },
    {
        "loss": 0.8768,
        "grad_norm": 0.25092560052871704,
        "learning_rate": 9.286224125624554e-05,
        "epoch": 0.21
    },
    {
        "loss": 0.8264,
        "grad_norm": 0.23783814907073975,
        "learning_rate": 9.21484653818701e-05,
        "epoch": 0.24
    },
    {
        "loss": 0.7512,
        "grad_norm": 0.12474504113197327,
        "learning_rate": 9.143468950749466e-05,
        "epoch": 0.26
    },
    {
        "loss": 0.689,
        "grad_norm": 0.1291741579771042,
        "learning_rate": 9.07209136331192e-05,
        "epoch": 0.28
    },
    {
        "loss": 0.6662,
        "grad_norm": 0.09967576712369919,
        "learning_rate": 9.000713775874375e-05,
        "epoch": 0.3
    },
    {
        "loss": 0.6632,
        "grad_norm": 0.10666831582784653,
        "learning_rate": 8.929336188436831e-05,
        "epoch": 0.32
    },
    {
        "loss": 0.598,
        "grad_norm": 0.10246028751134872,
        "learning_rate": 8.857958600999287e-05,
        "epoch": 0.34
    },
    {
        "loss": 0.5522,
        "grad_norm": 0.14087076485157013,
        "learning_rate": 8.786581013561742e-05,
        "epoch": 0.36
    },
    {
        "loss": 0.5128,
        "grad_norm": 0.10388721525669098,
        "learning_rate": 8.715203426124198e-05,
        "epoch": 0.39
    },
    {
        "loss": 0.4921,
        "grad_norm": 0.03953462466597557,
        "learning_rate": 8.643825838686654e-05,
        "epoch": 0.41
    },
    {
        "loss": 0.4967,
        "grad_norm": 0.024435456842184067,
        "learning_rate": 8.572448251249108e-05,
        "epoch": 0.43
    },
    {
        "loss": 0.4835,
        "grad_norm": 0.03168610483407974,
        "learning_rate": 8.501070663811563e-05,
        "epoch": 0.45
    },
    {
        "loss": 0.4852,
        "grad_norm": 0.02864435501396656,
        "learning_rate": 8.429693076374019e-05,
        "epoch": 0.47
    },
    {
        "loss": 0.4843,
        "grad_norm": 0.019934464246034622,
        "learning_rate": 8.358315488936475e-05,
        "epoch": 0.49
    },
    {
        "loss": 0.4809,
        "grad_norm": 0.026786329224705696,
        "learning_rate": 8.28693790149893e-05,
        "epoch": 0.51
    },
    {
        "loss": 0.478,
        "grad_norm": 0.027579033747315407,
        "learning_rate": 8.215560314061384e-05,
        "epoch": 0.54
    },
    {
        "loss": 0.4672,
        "grad_norm": 0.02496512606739998,
        "learning_rate": 8.14418272662384e-05,
        "epoch": 0.56
    },
    {
        "loss": 0.4838,
        "grad_norm": 0.022729717195034027,
        "learning_rate": 8.072805139186296e-05,
        "epoch": 0.58
    },
    {
        "loss": 0.4617,
        "grad_norm": 0.016038980334997177,
        "learning_rate": 8.001427551748751e-05,
        "epoch": 0.6
    },
    {
        "loss": 0.4463,
        "grad_norm": 0.036247607320547104,
        "learning_rate": 7.930049964311207e-05,
        "epoch": 0.62
    },
    {
        "loss": 0.4593,
        "grad_norm": 0.026976490393280983,
        "learning_rate": 7.858672376873663e-05,
        "epoch": 0.64
    },
    {
        "loss": 0.4783,
        "grad_norm": 0.028010347858071327,
        "learning_rate": 7.787294789436116e-05,
        "epoch": 0.66
    },
    {
        "loss": 0.4759,
        "grad_norm": 0.025455443188548088,
        "learning_rate": 7.715917201998572e-05,
        "epoch": 0.68
    },
    {
        "loss": 0.4428,
        "grad_norm": 0.028429454192519188,
        "learning_rate": 7.644539614561028e-05,
        "epoch": 0.71
    },
    {
        "loss": 0.4544,
        "grad_norm": 0.03145114332437515,
        "learning_rate": 7.573162027123484e-05,
        "epoch": 0.73
    },
    {
        "loss": 0.4476,
        "grad_norm": 0.027194702997803688,
        "learning_rate": 7.501784439685939e-05,
        "epoch": 0.75
    },
    {
        "loss": 0.4392,
        "grad_norm": 0.028238674625754356,
        "learning_rate": 7.430406852248394e-05,
        "epoch": 0.77
    },
    {
        "loss": 0.4522,
        "grad_norm": 0.02827240712940693,
        "learning_rate": 7.35902926481085e-05,
        "epoch": 0.79
    },
    {
        "loss": 0.4784,
        "grad_norm": 0.02908371016383171,
        "learning_rate": 7.287651677373304e-05,
        "epoch": 0.81
    },
    {
        "loss": 0.4707,
        "grad_norm": 0.028426991775631905,
        "learning_rate": 7.21627408993576e-05,
        "epoch": 0.83
    },
    {
        "loss": 0.4588,
        "grad_norm": 0.027172207832336426,
        "learning_rate": 7.144896502498216e-05,
        "epoch": 0.86
    },
    {
        "loss": 0.4412,
        "grad_norm": 0.02610703371465206,
        "learning_rate": 7.073518915060672e-05,
        "epoch": 0.88
    },
    {
        "loss": 0.4482,
        "grad_norm": 0.020694518461823463,
        "learning_rate": 7.002141327623126e-05,
        "epoch": 0.9
    },
    {
        "loss": 0.4561,
        "grad_norm": 0.024311622604727745,
        "learning_rate": 6.930763740185582e-05,
        "epoch": 0.92
    },
    {
        "loss": 0.4527,
        "grad_norm": 0.02004258707165718,
        "learning_rate": 6.859386152748038e-05,
        "epoch": 0.94
    },
    {
        "loss": 0.4393,
        "grad_norm": 0.031189335510134697,
        "learning_rate": 6.788008565310494e-05,
        "epoch": 0.96
    },
    {
        "loss": 0.4469,
        "grad_norm": 0.028964897617697716,
        "learning_rate": 6.716630977872948e-05,
        "epoch": 0.98
    },
    {
        "loss": 0.4235,
        "grad_norm": 0.025487752631306648,
        "learning_rate": 6.645253390435403e-05,
        "epoch": 1.0
    },
    {
        "loss": 0.469,
        "grad_norm": 0.03241824358701706,
        "learning_rate": 6.573875802997859e-05,
        "epoch": 1.03
    },
    {
        "loss": 0.4316,
        "grad_norm": 0.025556322187185287,
        "learning_rate": 6.502498215560314e-05,
        "epoch": 1.05
    },
    {
        "loss": 0.4641,
        "grad_norm": 0.03347189724445343,
        "learning_rate": 6.43112062812277e-05,
        "epoch": 1.07
    },
    {
        "loss": 0.4862,
        "grad_norm": 0.028542356565594673,
        "learning_rate": 6.359743040685226e-05,
        "epoch": 1.09
    },
    {
        "loss": 0.4544,
        "grad_norm": 0.027364244684576988,
        "learning_rate": 6.288365453247682e-05,
        "epoch": 1.11
    },
    {
        "loss": 0.4487,
        "grad_norm": 0.03194115683436394,
        "learning_rate": 6.216987865810135e-05,
        "epoch": 1.13
    },
    {
        "loss": 0.4574,
        "grad_norm": 0.023892013356089592,
        "learning_rate": 6.145610278372591e-05,
        "epoch": 1.15
    },
    {
        "loss": 0.3917,
        "grad_norm": 0.021957211196422577,
        "learning_rate": 6.074232690935047e-05,
        "epoch": 1.18
    },
    {
        "loss": 0.4626,
        "grad_norm": 0.02739725634455681,
        "learning_rate": 6.002855103497502e-05,
        "epoch": 1.2
    },
    {
        "loss": 0.4432,
        "grad_norm": 0.022175848484039307,
        "learning_rate": 5.9314775160599576e-05,
        "epoch": 1.22
    },
    {
        "loss": 0.4675,
        "grad_norm": 0.02222665585577488,
        "learning_rate": 5.860099928622412e-05,
        "epoch": 1.24
    },
    {
        "loss": 0.4768,
        "grad_norm": 0.030390148982405663,
        "learning_rate": 5.7887223411848676e-05,
        "epoch": 1.26
    },
    {
        "loss": 0.4313,
        "grad_norm": 0.043588969856500626,
        "learning_rate": 5.7173447537473236e-05,
        "epoch": 1.28
    },
    {
        "loss": 0.4361,
        "grad_norm": 0.024504538625478745,
        "learning_rate": 5.645967166309779e-05,
        "epoch": 1.3
    },
    {
        "loss": 0.4395,
        "grad_norm": 0.022183410823345184,
        "learning_rate": 5.574589578872235e-05,
        "epoch": 1.33
    },
    {
        "loss": 0.4483,
        "grad_norm": 0.03862762451171875,
        "learning_rate": 5.50321199143469e-05,
        "epoch": 1.35
    },
    {
        "loss": 0.4244,
        "grad_norm": 0.028182659298181534,
        "learning_rate": 5.431834403997145e-05,
        "epoch": 1.37
    },
    {
        "loss": 0.4279,
        "grad_norm": 0.025890139862895012,
        "learning_rate": 5.3604568165596e-05,
        "epoch": 1.39
    },
    {
        "loss": 0.4322,
        "grad_norm": 0.027043165639042854,
        "learning_rate": 5.2890792291220556e-05,
        "epoch": 1.41
    },
    {
        "loss": 0.4357,
        "grad_norm": 0.025264836847782135,
        "learning_rate": 5.2177016416845116e-05,
        "epoch": 1.43
    },
    {
        "loss": 0.4235,
        "grad_norm": 0.02370157279074192,
        "learning_rate": 5.146324054246967e-05,
        "epoch": 1.45
    },
    {
        "loss": 0.4578,
        "grad_norm": 0.026969408616423607,
        "learning_rate": 5.0749464668094216e-05,
        "epoch": 1.48
    },
    {
        "loss": 0.4484,
        "grad_norm": 0.02746378630399704,
        "learning_rate": 5.003568879371877e-05,
        "epoch": 1.5
    },
    {
        "loss": 0.4444,
        "grad_norm": 0.030153241008520126,
        "learning_rate": 4.932191291934333e-05,
        "epoch": 1.52
    },
    {
        "loss": 0.4293,
        "grad_norm": 0.03960558399558067,
        "learning_rate": 4.860813704496788e-05,
        "epoch": 1.54
    },
    {
        "loss": 0.4443,
        "grad_norm": 0.021408144384622574,
        "learning_rate": 4.7894361170592436e-05,
        "epoch": 1.56
    },
    {
        "loss": 0.4527,
        "grad_norm": 0.026018278673291206,
        "learning_rate": 4.718058529621699e-05,
        "epoch": 1.58
    },
    {
        "loss": 0.4412,
        "grad_norm": 0.02981044538319111,
        "learning_rate": 4.646680942184154e-05,
        "epoch": 1.6
    },
    {
        "loss": 0.4271,
        "grad_norm": 0.02796037122607231,
        "learning_rate": 4.5753033547466095e-05,
        "epoch": 1.62
    },
    {
        "loss": 0.4427,
        "grad_norm": 0.022666379809379578,
        "learning_rate": 4.503925767309065e-05,
        "epoch": 1.65
    },
    {
        "loss": 0.432,
        "grad_norm": 0.027316605672240257,
        "learning_rate": 4.432548179871521e-05,
        "epoch": 1.67
    },
    {
        "loss": 0.432,
        "grad_norm": 0.0241987481713295,
        "learning_rate": 4.3611705924339755e-05,
        "epoch": 1.69
    },
    {
        "loss": 0.4552,
        "grad_norm": 0.029560992494225502,
        "learning_rate": 4.2897930049964315e-05,
        "epoch": 1.71
    },
    {
        "loss": 0.4508,
        "grad_norm": 0.02799837477505207,
        "learning_rate": 4.218415417558887e-05,
        "epoch": 1.73
    },
    {
        "loss": 0.4292,
        "grad_norm": 0.02609708532691002,
        "learning_rate": 4.147037830121342e-05,
        "epoch": 1.75
    },
    {
        "loss": 0.4321,
        "grad_norm": 0.026239169761538506,
        "learning_rate": 4.0756602426837975e-05,
        "epoch": 1.77
    },
    {
        "loss": 0.4517,
        "grad_norm": 0.02065292000770569,
        "learning_rate": 4.004282655246253e-05,
        "epoch": 1.8
    },
    {
        "loss": 0.4106,
        "grad_norm": 0.02209210954606533,
        "learning_rate": 3.932905067808708e-05,
        "epoch": 1.82
    },
    {
        "loss": 0.437,
        "grad_norm": 0.03061533533036709,
        "learning_rate": 3.8615274803711635e-05,
        "epoch": 1.84
    },
    {
        "loss": 0.4149,
        "grad_norm": 0.029568705707788467,
        "learning_rate": 3.790149892933619e-05,
        "epoch": 1.86
    },
    {
        "loss": 0.4613,
        "grad_norm": 0.03470389172434807,
        "learning_rate": 3.718772305496074e-05,
        "epoch": 1.88
    },
    {
        "loss": 0.4619,
        "grad_norm": 0.024847520515322685,
        "learning_rate": 3.64739471805853e-05,
        "epoch": 1.9
    },
    {
        "loss": 0.4388,
        "grad_norm": 0.03276359289884567,
        "learning_rate": 3.576017130620985e-05,
        "epoch": 1.92
    },
    {
        "loss": 0.4414,
        "grad_norm": 0.03150138258934021,
        "learning_rate": 3.504639543183441e-05,
        "epoch": 1.95
    },
    {
        "loss": 0.4284,
        "grad_norm": 0.02568449079990387,
        "learning_rate": 3.433261955745896e-05,
        "epoch": 1.97
    },
    {
        "loss": 0.4502,
        "grad_norm": 0.03209845349192619,
        "learning_rate": 3.3618843683083515e-05,
        "epoch": 1.99
    },
    {
        "loss": 0.4089,
        "grad_norm": 0.02546289563179016,
        "learning_rate": 3.290506780870807e-05,
        "epoch": 2.01
    },
    {
        "loss": 0.449,
        "grad_norm": 0.032038215547800064,
        "learning_rate": 3.219129193433262e-05,
        "epoch": 2.03
    },
    {
        "loss": 0.4575,
        "grad_norm": 0.025153694674372673,
        "learning_rate": 3.1477516059957175e-05,
        "epoch": 2.05
    },
    {
        "loss": 0.4495,
        "grad_norm": 0.024598270654678345,
        "learning_rate": 3.076374018558173e-05,
        "epoch": 2.07
    },
    {
        "loss": 0.4379,
        "grad_norm": 0.03089691326022148,
        "learning_rate": 3.004996431120628e-05,
        "epoch": 2.09
    },
    {
        "loss": 0.4619,
        "grad_norm": 0.030782192945480347,
        "learning_rate": 2.9336188436830835e-05,
        "epoch": 2.12
    },
    {
        "loss": 0.4277,
        "grad_norm": 0.02943854220211506,
        "learning_rate": 2.862241256245539e-05,
        "epoch": 2.14
    },
    {
        "loss": 0.4111,
        "grad_norm": 0.023927738890051842,
        "learning_rate": 2.790863668807994e-05,
        "epoch": 2.16
    },
    {
        "loss": 0.4649,
        "grad_norm": 0.024980148300528526,
        "learning_rate": 2.7194860813704498e-05,
        "epoch": 2.18
    },
    {
        "loss": 0.4626,
        "grad_norm": 0.025051703676581383,
        "learning_rate": 2.6481084939329055e-05,
        "epoch": 2.2
    },
    {
        "loss": 0.4551,
        "grad_norm": 0.02557172253727913,
        "learning_rate": 2.5767309064953605e-05,
        "epoch": 2.22
    },
    {
        "loss": 0.4515,
        "grad_norm": 0.0302792526781559,
        "learning_rate": 2.505353319057816e-05,
        "epoch": 2.24
    },
    {
        "loss": 0.4336,
        "grad_norm": 0.0275727566331625,
        "learning_rate": 2.4339757316202715e-05,
        "epoch": 2.27
    },
    {
        "loss": 0.4191,
        "grad_norm": 0.035132136195898056,
        "learning_rate": 2.3625981441827268e-05,
        "epoch": 2.29
    },
    {
        "loss": 0.4236,
        "grad_norm": 0.03179348260164261,
        "learning_rate": 2.291220556745182e-05,
        "epoch": 2.31
    },
    {
        "loss": 0.4491,
        "grad_norm": 0.027887076139450073,
        "learning_rate": 2.2198429693076374e-05,
        "epoch": 2.33
    },
    {
        "loss": 0.4451,
        "grad_norm": 0.031316012144088745,
        "learning_rate": 2.1484653818700928e-05,
        "epoch": 2.35
    },
    {
        "loss": 0.4621,
        "grad_norm": 0.02915504388511181,
        "learning_rate": 2.0770877944325484e-05,
        "epoch": 2.37
    },
    {
        "loss": 0.4454,
        "grad_norm": 0.025588663294911385,
        "learning_rate": 2.0057102069950038e-05,
        "epoch": 2.39
    },
    {
        "loss": 0.4239,
        "grad_norm": 0.027777114883065224,
        "learning_rate": 1.934332619557459e-05,
        "epoch": 2.42
    },
    {
        "loss": 0.4345,
        "grad_norm": 0.026019154116511345,
        "learning_rate": 1.8629550321199144e-05,
        "epoch": 2.44
    },
    {
        "loss": 0.4319,
        "grad_norm": 0.02473517321050167,
        "learning_rate": 1.79157744468237e-05,
        "epoch": 2.46
    },
    {
        "loss": 0.4359,
        "grad_norm": 0.02791382186114788,
        "learning_rate": 1.720199857244825e-05,
        "epoch": 2.48
    },
    {
        "loss": 0.4353,
        "grad_norm": 0.0315752774477005,
        "learning_rate": 1.6488222698072804e-05,
        "epoch": 2.5
    },
    {
        "loss": 0.4316,
        "grad_norm": 0.02935102954506874,
        "learning_rate": 1.5774446823697357e-05,
        "epoch": 2.52
    },
    {
        "loss": 0.4526,
        "grad_norm": 0.028289074078202248,
        "learning_rate": 1.5060670949321914e-05,
        "epoch": 2.54
    },
    {
        "loss": 0.4255,
        "grad_norm": 0.03214814513921738,
        "learning_rate": 1.4346895074946467e-05,
        "epoch": 2.57
    },
    {
        "loss": 0.4377,
        "grad_norm": 0.030067548155784607,
        "learning_rate": 1.363311920057102e-05,
        "epoch": 2.59
    },
    {
        "loss": 0.4368,
        "grad_norm": 0.020380619913339615,
        "learning_rate": 1.2919343326195577e-05,
        "epoch": 2.61
    },
    {
        "loss": 0.4372,
        "grad_norm": 0.024811651557683945,
        "learning_rate": 1.2205567451820129e-05,
        "epoch": 2.63
    },
    {
        "loss": 0.4294,
        "grad_norm": 0.026744719594717026,
        "learning_rate": 1.1491791577444682e-05,
        "epoch": 2.65
    },
    {
        "loss": 0.4189,
        "grad_norm": 0.02485615760087967,
        "learning_rate": 1.0778015703069237e-05,
        "epoch": 2.67
    },
    {
        "loss": 0.4319,
        "grad_norm": 0.032076913863420486,
        "learning_rate": 1.006423982869379e-05,
        "epoch": 2.69
    },
    {
        "loss": 0.4486,
        "grad_norm": 0.02868652157485485,
        "learning_rate": 9.350463954318345e-06,
        "epoch": 2.71
    },
    {
        "loss": 0.438,
        "grad_norm": 0.03174731135368347,
        "learning_rate": 8.636688079942897e-06,
        "epoch": 2.74
    },
    {
        "loss": 0.4482,
        "grad_norm": 0.023561615496873856,
        "learning_rate": 7.922912205567452e-06,
        "epoch": 2.76
    },
    {
        "loss": 0.4293,
        "grad_norm": 0.02965576946735382,
        "learning_rate": 7.209136331192005e-06,
        "epoch": 2.78
    },
    {
        "loss": 0.437,
        "grad_norm": 0.02711855247616768,
        "learning_rate": 6.49536045681656e-06,
        "epoch": 2.8
    },
    {
        "loss": 0.4334,
        "grad_norm": 0.026889901608228683,
        "learning_rate": 5.781584582441114e-06,
        "epoch": 2.82
    },
    {
        "loss": 0.4234,
        "grad_norm": 0.028478335589170456,
        "learning_rate": 5.067808708065668e-06,
        "epoch": 2.84
    },
    {
        "loss": 0.4747,
        "grad_norm": 0.027831507846713066,
        "learning_rate": 4.354032833690221e-06,
        "epoch": 2.86
    },
    {
        "loss": 0.4284,
        "grad_norm": 0.02989758364856243,
        "learning_rate": 3.640256959314775e-06,
        "epoch": 2.89
    },
    {
        "loss": 0.4208,
        "grad_norm": 0.024253638461232185,
        "learning_rate": 2.9264810849393293e-06,
        "epoch": 2.91
    },
    {
        "loss": 0.4196,
        "grad_norm": 0.024433979764580727,
        "learning_rate": 2.212705210563883e-06,
        "epoch": 2.93
    },
    {
        "loss": 0.4264,
        "grad_norm": 0.028678178787231445,
        "learning_rate": 1.498929336188437e-06,
        "epoch": 2.95
    },
    {
        "loss": 0.4242,
        "grad_norm": 0.02417754754424095,
        "learning_rate": 7.851534618129908e-07,
        "epoch": 2.97
    },
    {
        "loss": 0.4074,
        "grad_norm": 0.030433783307671547,
        "learning_rate": 7.137758743754461e-08,
        "epoch": 2.99
    }
]