[
    {
        "loss": 0.9944,
        "grad_norm": 0.004386806394904852,
        "learning_rate": 9.928622412562456e-05,
        "epoch": 0.02
    },
    {
        "loss": 1.1046,
        "grad_norm": 0.016571078449487686,
        "learning_rate": 9.857244825124911e-05,
        "epoch": 0.04
    },
    {
        "loss": 1.0254,
        "grad_norm": 0.0412806011736393,
        "learning_rate": 9.785867237687366e-05,
        "epoch": 0.06
    },
    {
        "loss": 1.0259,
        "grad_norm": 0.1051078662276268,
        "learning_rate": 9.714489650249822e-05,
        "epoch": 0.09
    },
    {
        "loss": 1.036,
        "grad_norm": 0.1894785612821579,
        "learning_rate": 9.643112062812278e-05,
        "epoch": 0.11
    },
    {
        "loss": 1.0348,
        "grad_norm": 0.20283809304237366,
        "learning_rate": 9.571734475374732e-05,
        "epoch": 0.13
    },
    {
        "loss": 1.0111,
        "grad_norm": 0.4786430895328522,
        "learning_rate": 9.500356887937188e-05,
        "epoch": 0.15
    },
    {
        "loss": 0.9254,
        "grad_norm": 0.3237532079219818,
        "learning_rate": 9.428979300499644e-05,
        "epoch": 0.17
    },
    {
        "loss": 0.8662,
        "grad_norm": 0.5355044007301331,
        "learning_rate": 9.357601713062099e-05,
        "epoch": 0.19
    },
    {
        "loss": 0.7378,
        "grad_norm": 0.17129851877689362,
        "learning_rate": 9.286224125624554e-05,
        "epoch": 0.21
    },
    {
        "loss": 0.7177,
        "grad_norm": 0.21589304506778717,
        "learning_rate": 9.21484653818701e-05,
        "epoch": 0.24
    },
    {
        "loss": 0.6677,
        "grad_norm": 0.18830358982086182,
        "learning_rate": 9.143468950749466e-05,
        "epoch": 0.26
    },
    {
        "loss": 0.615,
        "grad_norm": 0.2101079821586609,
        "learning_rate": 9.07209136331192e-05,
        "epoch": 0.28
    },
    {
        "loss": 0.575,
        "grad_norm": 0.19579526782035828,
        "learning_rate": 9.000713775874375e-05,
        "epoch": 0.3
    },
    {
        "loss": 0.5486,
        "grad_norm": 0.13639992475509644,
        "learning_rate": 8.929336188436831e-05,
        "epoch": 0.32
    },
    {
        "loss": 0.4903,
        "grad_norm": 0.044367652386426926,
        "learning_rate": 8.857958600999287e-05,
        "epoch": 0.34
    },
    {
        "loss": 0.4768,
        "grad_norm": 0.036564406007528305,
        "learning_rate": 8.786581013561742e-05,
        "epoch": 0.36
    },
    {
        "loss": 0.4714,
        "grad_norm": 0.02924272045493126,
        "learning_rate": 8.715203426124198e-05,
        "epoch": 0.39
    },
    {
        "loss": 0.4751,
        "grad_norm": 0.032245974987745285,
        "learning_rate": 8.643825838686654e-05,
        "epoch": 0.41
    },
    {
        "loss": 0.4869,
        "grad_norm": 0.029520966112613678,
        "learning_rate": 8.572448251249108e-05,
        "epoch": 0.43
    },
    {
        "loss": 0.4743,
        "grad_norm": 0.04791213572025299,
        "learning_rate": 8.501070663811563e-05,
        "epoch": 0.45
    },
    {
        "loss": 0.4762,
        "grad_norm": 0.04669865220785141,
        "learning_rate": 8.429693076374019e-05,
        "epoch": 0.47
    },
    {
        "loss": 0.4768,
        "grad_norm": 0.03241864964365959,
        "learning_rate": 8.358315488936475e-05,
        "epoch": 0.49
    },
    {
        "loss": 0.4729,
        "grad_norm": 0.04385261982679367,
        "learning_rate": 8.28693790149893e-05,
        "epoch": 0.51
    },
    {
        "loss": 0.4703,
        "grad_norm": 0.04516860470175743,
        "learning_rate": 8.215560314061384e-05,
        "epoch": 0.54
    },
    {
        "loss": 0.459,
        "grad_norm": 0.03650428727269173,
        "learning_rate": 8.14418272662384e-05,
        "epoch": 0.56
    },
    {
        "loss": 0.4753,
        "grad_norm": 0.03481019288301468,
        "learning_rate": 8.072805139186296e-05,
        "epoch": 0.58
    },
    {
        "loss": 0.4537,
        "grad_norm": 0.024086346849799156,
        "learning_rate": 8.001427551748751e-05,
        "epoch": 0.6
    },
    {
        "loss": 0.4377,
        "grad_norm": 0.061280108988285065,
        "learning_rate": 7.930049964311207e-05,
        "epoch": 0.62
    },
    {
        "loss": 0.4513,
        "grad_norm": 0.0420377142727375,
        "learning_rate": 7.858672376873663e-05,
        "epoch": 0.64
    },
    {
        "loss": 0.4694,
        "grad_norm": 0.04787536337971687,
        "learning_rate": 7.787294789436116e-05,
        "epoch": 0.66
    },
    {
        "loss": 0.4674,
        "grad_norm": 0.040967054665088654,
        "learning_rate": 7.715917201998572e-05,
        "epoch": 0.68
    },
    {
        "loss": 0.4343,
        "grad_norm": 0.04158984497189522,
        "learning_rate": 7.644539614561028e-05,
        "epoch": 0.71
    },
    {
        "loss": 0.4463,
        "grad_norm": 0.0408501923084259,
        "learning_rate": 7.573162027123484e-05,
        "epoch": 0.73
    },
    {
        "loss": 0.4384,
        "grad_norm": 0.043052636086940765,
        "learning_rate": 7.501784439685939e-05,
        "epoch": 0.75
    },
    {
        "loss": 0.4324,
        "grad_norm": 0.0415349155664444,
        "learning_rate": 7.430406852248394e-05,
        "epoch": 0.77
    },
    {
        "loss": 0.4448,
        "grad_norm": 0.03455277904868126,
        "learning_rate": 7.35902926481085e-05,
        "epoch": 0.79
    },
    {
        "loss": 0.4706,
        "grad_norm": 0.046726908534765244,
        "learning_rate": 7.287651677373304e-05,
        "epoch": 0.81
    },
    {
        "loss": 0.4629,
        "grad_norm": 0.03931969404220581,
        "learning_rate": 7.21627408993576e-05,
        "epoch": 0.83
    },
    {
        "loss": 0.4522,
        "grad_norm": 0.04138951003551483,
        "learning_rate": 7.144896502498216e-05,
        "epoch": 0.86
    },
    {
        "loss": 0.4333,
        "grad_norm": 0.03572777286171913,
        "learning_rate": 7.073518915060672e-05,
        "epoch": 0.88
    },
    {
        "loss": 0.4418,
        "grad_norm": 0.029513681307435036,
        "learning_rate": 7.002141327623126e-05,
        "epoch": 0.9
    },
    {
        "loss": 0.4497,
        "grad_norm": 0.035230956971645355,
        "learning_rate": 6.930763740185582e-05,
        "epoch": 0.92
    },
    {
        "loss": 0.4469,
        "grad_norm": 0.02717871032655239,
        "learning_rate": 6.859386152748038e-05,
        "epoch": 0.94
    },
    {
        "loss": 0.434,
        "grad_norm": 0.044743847101926804,
        "learning_rate": 6.788008565310494e-05,
        "epoch": 0.96
    },
    {
        "loss": 0.4421,
        "grad_norm": 0.03194499760866165,
        "learning_rate": 6.716630977872948e-05,
        "epoch": 0.98
    },
    {
        "loss": 0.4174,
        "grad_norm": 0.03666350618004799,
        "learning_rate": 6.645253390435403e-05,
        "epoch": 1.0
    },
    {
        "loss": 0.4644,
        "grad_norm": 0.042113080620765686,
        "learning_rate": 6.573875802997859e-05,
        "epoch": 1.03
    },
    {
        "loss": 0.4265,
        "grad_norm": 0.0344017893075943,
        "learning_rate": 6.502498215560314e-05,
        "epoch": 1.05
    },
    {
        "loss": 0.4598,
        "grad_norm": 0.04959132522344589,
        "learning_rate": 6.43112062812277e-05,
        "epoch": 1.07
    },
    {
        "loss": 0.481,
        "grad_norm": 0.043193984776735306,
        "learning_rate": 6.359743040685226e-05,
        "epoch": 1.09
    },
    {
        "loss": 0.4493,
        "grad_norm": 0.03906489908695221,
        "learning_rate": 6.288365453247682e-05,
        "epoch": 1.11
    },
    {
        "loss": 0.4437,
        "grad_norm": 0.04664844274520874,
        "learning_rate": 6.216987865810135e-05,
        "epoch": 1.13
    },
    {
        "loss": 0.4534,
        "grad_norm": 0.03181974217295647,
        "learning_rate": 6.145610278372591e-05,
        "epoch": 1.15
    },
    {
        "loss": 0.3876,
        "grad_norm": 0.029420504346489906,
        "learning_rate": 6.074232690935047e-05,
        "epoch": 1.18
    },
    {
        "loss": 0.4589,
        "grad_norm": 0.03656977787613869,
        "learning_rate": 6.002855103497502e-05,
        "epoch": 1.2
    },
    {
        "loss": 0.4393,
        "grad_norm": 0.032870836555957794,
        "learning_rate": 5.9314775160599576e-05,
        "epoch": 1.22
    },
    {
        "loss": 0.4635,
        "grad_norm": 0.033338624984025955,
        "learning_rate": 5.860099928622412e-05,
        "epoch": 1.24
    },
    {
        "loss": 0.4724,
        "grad_norm": 0.04321107640862465,
        "learning_rate": 5.7887223411848676e-05,
        "epoch": 1.26
    },
    {
        "loss": 0.4274,
        "grad_norm": 0.06329197436571121,
        "learning_rate": 5.7173447537473236e-05,
        "epoch": 1.28
    },
    {
        "loss": 0.4322,
        "grad_norm": 0.03097091242671013,
        "learning_rate": 5.645967166309779e-05,
        "epoch": 1.3
    },
    {
        "loss": 0.4355,
        "grad_norm": 0.028957651928067207,
        "learning_rate": 5.574589578872235e-05,
        "epoch": 1.33
    },
    {
        "loss": 0.4439,
        "grad_norm": 0.05717412009835243,
        "learning_rate": 5.50321199143469e-05,
        "epoch": 1.35
    },
    {
        "loss": 0.4208,
        "grad_norm": 0.039911456406116486,
        "learning_rate": 5.431834403997145e-05,
        "epoch": 1.37
    },
    {
        "loss": 0.4246,
        "grad_norm": 0.03676115348935127,
        "learning_rate": 5.3604568165596e-05,
        "epoch": 1.39
    },
    {
        "loss": 0.4276,
        "grad_norm": 0.03709148243069649,
        "learning_rate": 5.2890792291220556e-05,
        "epoch": 1.41
    },
    {
        "loss": 0.4327,
        "grad_norm": 0.04205397889018059,
        "learning_rate": 5.2177016416845116e-05,
        "epoch": 1.43
    },
    {
        "loss": 0.42,
        "grad_norm": 0.031822569668293,
        "learning_rate": 5.146324054246967e-05,
        "epoch": 1.45
    },
    {
        "loss": 0.4545,
        "grad_norm": 0.03718692436814308,
        "learning_rate": 5.0749464668094216e-05,
        "epoch": 1.48
    },
    {
        "loss": 0.445,
        "grad_norm": 0.0375525988638401,
        "learning_rate": 5.003568879371877e-05,
        "epoch": 1.5
    },
    {
        "loss": 0.4411,
        "grad_norm": 0.046279843896627426,
        "learning_rate": 4.932191291934333e-05,
        "epoch": 1.52
    },
    {
        "loss": 0.4251,
        "grad_norm": 0.04938305914402008,
        "learning_rate": 4.860813704496788e-05,
        "epoch": 1.54
    },
    {
        "loss": 0.4407,
        "grad_norm": 0.03184446319937706,
        "learning_rate": 4.7894361170592436e-05,
        "epoch": 1.56
    },
    {
        "loss": 0.4494,
        "grad_norm": 0.03509773313999176,
        "learning_rate": 4.718058529621699e-05,
        "epoch": 1.58
    },
    {
        "loss": 0.4378,
        "grad_norm": 0.0384644977748394,
        "learning_rate": 4.646680942184154e-05,
        "epoch": 1.6
    },
    {
        "loss": 0.4236,
        "grad_norm": 0.03663147985935211,
        "learning_rate": 4.5753033547466095e-05,
        "epoch": 1.62
    },
    {
        "loss": 0.4399,
        "grad_norm": 0.03169850632548332,
        "learning_rate": 4.503925767309065e-05,
        "epoch": 1.65
    },
    {
        "loss": 0.4288,
        "grad_norm": 0.03935273736715317,
        "learning_rate": 4.432548179871521e-05,
        "epoch": 1.67
    },
    {
        "loss": 0.4292,
        "grad_norm": 0.03462138772010803,
        "learning_rate": 4.3611705924339755e-05,
        "epoch": 1.69
    },
    {
        "loss": 0.4521,
        "grad_norm": 0.0420030802488327,
        "learning_rate": 4.2897930049964315e-05,
        "epoch": 1.71
    },
    {
        "loss": 0.4468,
        "grad_norm": 0.03731948137283325,
        "learning_rate": 4.218415417558887e-05,
        "epoch": 1.73
    },
    {
        "loss": 0.4257,
        "grad_norm": 0.03675698861479759,
        "learning_rate": 4.147037830121342e-05,
        "epoch": 1.75
    },
    {
        "loss": 0.4289,
        "grad_norm": 0.038486238569021225,
        "learning_rate": 4.0756602426837975e-05,
        "epoch": 1.77
    },
    {
        "loss": 0.4483,
        "grad_norm": 0.029391350224614143,
        "learning_rate": 4.004282655246253e-05,
        "epoch": 1.8
    },
    {
        "loss": 0.4074,
        "grad_norm": 0.030862843617796898,
        "learning_rate": 3.932905067808708e-05,
        "epoch": 1.82
    },
    {
        "loss": 0.4331,
        "grad_norm": 0.046355489641427994,
        "learning_rate": 3.8615274803711635e-05,
        "epoch": 1.84
    },
    {
        "loss": 0.4112,
        "grad_norm": 0.04376225918531418,
        "learning_rate": 3.790149892933619e-05,
        "epoch": 1.86
    },
    {
        "loss": 0.4577,
        "grad_norm": 0.04703524708747864,
        "learning_rate": 3.718772305496074e-05,
        "epoch": 1.88
    },
    {
        "loss": 0.4584,
        "grad_norm": 0.03535117208957672,
        "learning_rate": 3.64739471805853e-05,
        "epoch": 1.9
    },
    {
        "loss": 0.436,
        "grad_norm": 0.045841507613658905,
        "learning_rate": 3.576017130620985e-05,
        "epoch": 1.92
    },
    {
        "loss": 0.4387,
        "grad_norm": 0.04580831900238991,
        "learning_rate": 3.504639543183441e-05,
        "epoch": 1.95
    },
    {
        "loss": 0.4254,
        "grad_norm": 0.03542289882898331,
        "learning_rate": 3.433261955745896e-05,
        "epoch": 1.97
    },
    {
        "loss": 0.4468,
        "grad_norm": 0.049024004489183426,
        "learning_rate": 3.3618843683083515e-05,
        "epoch": 1.99
    },
    {
        "loss": 0.4045,
        "grad_norm": 0.036618221551179886,
        "learning_rate": 3.290506780870807e-05,
        "epoch": 2.01
    },
    {
        "loss": 0.4454,
        "grad_norm": 0.04248905926942825,
        "learning_rate": 3.219129193433262e-05,
        "epoch": 2.03
    },
    {
        "loss": 0.4542,
        "grad_norm": 0.03464933857321739,
        "learning_rate": 3.1477516059957175e-05,
        "epoch": 2.05
    },
    {
        "loss": 0.4461,
        "grad_norm": 0.03434768319129944,
        "learning_rate": 3.076374018558173e-05,
        "epoch": 2.07
    },
    {
        "loss": 0.434,
        "grad_norm": 0.039565205574035645,
        "learning_rate": 3.004996431120628e-05,
        "epoch": 2.09
    },
    {
        "loss": 0.4584,
        "grad_norm": 0.041976913809776306,
        "learning_rate": 2.9336188436830835e-05,
        "epoch": 2.12
    },
    {
        "loss": 0.4249,
        "grad_norm": 0.04104467108845711,
        "learning_rate": 2.862241256245539e-05,
        "epoch": 2.14
    },
    {
        "loss": 0.4075,
        "grad_norm": 0.0335342176258564,
        "learning_rate": 2.790863668807994e-05,
        "epoch": 2.16
    },
    {
        "loss": 0.4612,
        "grad_norm": 0.03640250861644745,
        "learning_rate": 2.7194860813704498e-05,
        "epoch": 2.18
    },
    {
        "loss": 0.4586,
        "grad_norm": 0.03541048988699913,
        "learning_rate": 2.6481084939329055e-05,
        "epoch": 2.2
    },
    {
        "loss": 0.452,
        "grad_norm": 0.034817084670066833,
        "learning_rate": 2.5767309064953605e-05,
        "epoch": 2.22
    },
    {
        "loss": 0.4468,
        "grad_norm": 0.03979550302028656,
        "learning_rate": 2.505353319057816e-05,
        "epoch": 2.24
    },
    {
        "loss": 0.4299,
        "grad_norm": 0.039040457457304,
        "learning_rate": 2.4339757316202715e-05,
        "epoch": 2.27
    },
    {
        "loss": 0.4166,
        "grad_norm": 0.05042151361703873,
        "learning_rate": 2.3625981441827268e-05,
        "epoch": 2.29
    },
    {
        "loss": 0.4204,
        "grad_norm": 0.03618672117590904,
        "learning_rate": 2.291220556745182e-05,
        "epoch": 2.31
    },
    {
        "loss": 0.446,
        "grad_norm": 0.038902804255485535,
        "learning_rate": 2.2198429693076374e-05,
        "epoch": 2.33
    },
    {
        "loss": 0.4417,
        "grad_norm": 0.042221035808324814,
        "learning_rate": 2.1484653818700928e-05,
        "epoch": 2.35
    },
    {
        "loss": 0.4592,
        "grad_norm": 0.04186815395951271,
        "learning_rate": 2.0770877944325484e-05,
        "epoch": 2.37
    },
    {
        "loss": 0.4417,
        "grad_norm": 0.03812314197421074,
        "learning_rate": 2.0057102069950038e-05,
        "epoch": 2.39
    },
    {
        "loss": 0.4206,
        "grad_norm": 0.04116662219166756,
        "learning_rate": 1.934332619557459e-05,
        "epoch": 2.42
    },
    {
        "loss": 0.4313,
        "grad_norm": 0.036305587738752365,
        "learning_rate": 1.8629550321199144e-05,
        "epoch": 2.44
    },
    {
        "loss": 0.4291,
        "grad_norm": 0.03553004935383797,
        "learning_rate": 1.79157744468237e-05,
        "epoch": 2.46
    },
    {
        "loss": 0.4329,
        "grad_norm": 0.039863236248493195,
        "learning_rate": 1.720199857244825e-05,
        "epoch": 2.48
    },
    {
        "loss": 0.4314,
        "grad_norm": 0.045565057545900345,
        "learning_rate": 1.6488222698072804e-05,
        "epoch": 2.5
    },
    {
        "loss": 0.4275,
        "grad_norm": 0.041757456958293915,
        "learning_rate": 1.5774446823697357e-05,
        "epoch": 2.52
    },
    {
        "loss": 0.4489,
        "grad_norm": 0.03924712538719177,
        "learning_rate": 1.5060670949321914e-05,
        "epoch": 2.54
    },
    {
        "loss": 0.4224,
        "grad_norm": 0.046548180282115936,
        "learning_rate": 1.4346895074946467e-05,
        "epoch": 2.57
    },
    {
        "loss": 0.4333,
        "grad_norm": 0.041759394109249115,
        "learning_rate": 1.363311920057102e-05,
        "epoch": 2.59
    },
    {
        "loss": 0.4342,
        "grad_norm": 0.02833406813442707,
        "learning_rate": 1.2919343326195577e-05,
        "epoch": 2.61
    },
    {
        "loss": 0.4341,
        "grad_norm": 0.03828193247318268,
        "learning_rate": 1.2205567451820129e-05,
        "epoch": 2.63
    },
    {
        "loss": 0.4264,
        "grad_norm": 0.03794441744685173,
        "learning_rate": 1.1491791577444682e-05,
        "epoch": 2.65
    },
    {
        "loss": 0.4157,
        "grad_norm": 0.0355222187936306,
        "learning_rate": 1.0778015703069237e-05,
        "epoch": 2.67
    },
    {
        "loss": 0.4287,
        "grad_norm": 0.04351673647761345,
        "learning_rate": 1.006423982869379e-05,
        "epoch": 2.69
    },
    {
        "loss": 0.4451,
        "grad_norm": 0.040892064571380615,
        "learning_rate": 9.350463954318345e-06,
        "epoch": 2.71
    },
    {
        "loss": 0.4341,
        "grad_norm": 0.044611163437366486,
        "learning_rate": 8.636688079942897e-06,
        "epoch": 2.74
    },
    {
        "loss": 0.4451,
        "grad_norm": 0.03195914626121521,
        "learning_rate": 7.922912205567452e-06,
        "epoch": 2.76
    },
    {
        "loss": 0.4256,
        "grad_norm": 0.04206361249089241,
        "learning_rate": 7.209136331192005e-06,
        "epoch": 2.78
    },
    {
        "loss": 0.4331,
        "grad_norm": 0.03897469490766525,
        "learning_rate": 6.49536045681656e-06,
        "epoch": 2.8
    },
    {
        "loss": 0.4298,
        "grad_norm": 0.03872392326593399,
        "learning_rate": 5.781584582441114e-06,
        "epoch": 2.82
    },
    {
        "loss": 0.4196,
        "grad_norm": 0.04041345417499542,
        "learning_rate": 5.067808708065668e-06,
        "epoch": 2.84
    },
    {
        "loss": 0.4713,
        "grad_norm": 0.03930777311325073,
        "learning_rate": 4.354032833690221e-06,
        "epoch": 2.86
    },
    {
        "loss": 0.4252,
        "grad_norm": 0.042297057807445526,
        "learning_rate": 3.640256959314775e-06,
        "epoch": 2.89
    },
    {
        "loss": 0.4173,
        "grad_norm": 0.03377433493733406,
        "learning_rate": 2.9264810849393293e-06,
        "epoch": 2.91
    },
    {
        "loss": 0.4158,
        "grad_norm": 0.03575362265110016,
        "learning_rate": 2.212705210563883e-06,
        "epoch": 2.93
    },
    {
        "loss": 0.4232,
        "grad_norm": 0.040214356034994125,
        "learning_rate": 1.498929336188437e-06,
        "epoch": 2.95
    },
    {
        "loss": 0.4208,
        "grad_norm": 0.03526155650615692,
        "learning_rate": 7.851534618129908e-07,
        "epoch": 2.97
    },
    {
        "loss": 0.4036,
        "grad_norm": 0.043610043823719025,
        "learning_rate": 7.137758743754461e-08,
        "epoch": 2.99
    }
]