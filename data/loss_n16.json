[
    {
        "loss": 0.9944,
        "grad_norm": 0.0013610185123980045,
        "learning_rate": 9.928622412562456e-05,
        "epoch": 0.02
    },
    {
        "loss": 1.1044,
        "grad_norm": 0.0031420160084962845,
        "learning_rate": 9.857244825124911e-05,
        "epoch": 0.04
    },
    {
        "loss": 1.0259,
        "grad_norm": 0.005616705399006605,
        "learning_rate": 9.785867237687366e-05,
        "epoch": 0.06
    },
    {
        "loss": 1.0266,
        "grad_norm": 0.010747342370450497,
        "learning_rate": 9.714489650249822e-05,
        "epoch": 0.09
    },
    {
        "loss": 1.0389,
        "grad_norm": 0.015873949974775314,
        "learning_rate": 9.643112062812278e-05,
        "epoch": 0.11
    },
    {
        "loss": 1.0462,
        "grad_norm": 0.015639306977391243,
        "learning_rate": 9.571734475374732e-05,
        "epoch": 0.13
    },
    {
        "loss": 1.0539,
        "grad_norm": 0.03086487576365471,
        "learning_rate": 9.500356887937188e-05,
        "epoch": 0.15
    },
    {
        "loss": 1.0235,
        "grad_norm": 0.02702808752655983,
        "learning_rate": 9.428979300499644e-05,
        "epoch": 0.17
    },
    {
        "loss": 1.0664,
        "grad_norm": 0.05115369334816933,
        "learning_rate": 9.357601713062099e-05,
        "epoch": 0.19
    },
    {
        "loss": 1.0026,
        "grad_norm": 0.0578649640083313,
        "learning_rate": 9.286224125624554e-05,
        "epoch": 0.21
    },
    {
        "loss": 1.027,
        "grad_norm": 0.0646226778626442,
        "learning_rate": 9.21484653818701e-05,
        "epoch": 0.24
    },
    {
        "loss": 0.9943,
        "grad_norm": 0.08547331392765045,
        "learning_rate": 9.143468950749466e-05,
        "epoch": 0.26
    },
    {
        "loss": 0.9055,
        "grad_norm": 0.07713637501001358,
        "learning_rate": 9.07209136331192e-05,
        "epoch": 0.28
    },
    {
        "loss": 0.8838,
        "grad_norm": 0.1016356572508812,
        "learning_rate": 9.000713775874375e-05,
        "epoch": 0.3
    },
    {
        "loss": 0.8607,
        "grad_norm": 0.09885922819375992,
        "learning_rate": 8.929336188436831e-05,
        "epoch": 0.32
    },
    {
        "loss": 0.7596,
        "grad_norm": 0.05734994262456894,
        "learning_rate": 8.857958600999287e-05,
        "epoch": 0.34
    },
    {
        "loss": 0.7155,
        "grad_norm": 0.04612499848008156,
        "learning_rate": 8.786581013561742e-05,
        "epoch": 0.36
    },
    {
        "loss": 0.6958,
        "grad_norm": 0.04272456839680672,
        "learning_rate": 8.715203426124198e-05,
        "epoch": 0.39
    },
    {
        "loss": 0.6838,
        "grad_norm": 0.04581791162490845,
        "learning_rate": 8.643825838686654e-05,
        "epoch": 0.41
    },
    {
        "loss": 0.681,
        "grad_norm": 0.04269356280565262,
        "learning_rate": 8.572448251249108e-05,
        "epoch": 0.43
    },
    {
        "loss": 0.6463,
        "grad_norm": 0.04976500943303108,
        "learning_rate": 8.501070663811563e-05,
        "epoch": 0.45
    },
    {
        "loss": 0.638,
        "grad_norm": 0.05066438391804695,
        "learning_rate": 8.429693076374019e-05,
        "epoch": 0.47
    },
    {
        "loss": 0.6091,
        "grad_norm": 0.039835210889577866,
        "learning_rate": 8.358315488936475e-05,
        "epoch": 0.49
    },
    {
        "loss": 0.5819,
        "grad_norm": 0.05123317241668701,
        "learning_rate": 8.28693790149893e-05,
        "epoch": 0.51
    },
    {
        "loss": 0.5566,
        "grad_norm": 0.06233510375022888,
        "learning_rate": 8.215560314061384e-05,
        "epoch": 0.54
    },
    {
        "loss": 0.5157,
        "grad_norm": 0.05521378293633461,
        "learning_rate": 8.14418272662384e-05,
        "epoch": 0.56
    },
    {
        "loss": 0.5162,
        "grad_norm": 0.021213147789239883,
        "learning_rate": 8.072805139186296e-05,
        "epoch": 0.58
    },
    {
        "loss": 0.4843,
        "grad_norm": 0.0140911303460598,
        "learning_rate": 8.001427551748751e-05,
        "epoch": 0.6
    },
    {
        "loss": 0.4661,
        "grad_norm": 0.020124152302742004,
        "learning_rate": 7.930049964311207e-05,
        "epoch": 0.62
    },
    {
        "loss": 0.4762,
        "grad_norm": 0.015401769429445267,
        "learning_rate": 7.858672376873663e-05,
        "epoch": 0.64
    },
    {
        "loss": 0.4974,
        "grad_norm": 0.013461688533425331,
        "learning_rate": 7.787294789436116e-05,
        "epoch": 0.66
    },
    {
        "loss": 0.4947,
        "grad_norm": 0.015497622080147266,
        "learning_rate": 7.715917201998572e-05,
        "epoch": 0.68
    },
    {
        "loss": 0.4609,
        "grad_norm": 0.014178442768752575,
        "learning_rate": 7.644539614561028e-05,
        "epoch": 0.71
    },
    {
        "loss": 0.4712,
        "grad_norm": 0.01666942983865738,
        "learning_rate": 7.573162027123484e-05,
        "epoch": 0.73
    },
    {
        "loss": 0.4671,
        "grad_norm": 0.013094332069158554,
        "learning_rate": 7.501784439685939e-05,
        "epoch": 0.75
    },
    {
        "loss": 0.4559,
        "grad_norm": 0.013836176134645939,
        "learning_rate": 7.430406852248394e-05,
        "epoch": 0.77
    },
    {
        "loss": 0.469,
        "grad_norm": 0.01527229230850935,
        "learning_rate": 7.35902926481085e-05,
        "epoch": 0.79
    },
    {
        "loss": 0.4938,
        "grad_norm": 0.015896419063210487,
        "learning_rate": 7.287651677373304e-05,
        "epoch": 0.81
    },
    {
        "loss": 0.4895,
        "grad_norm": 0.016012774780392647,
        "learning_rate": 7.21627408993576e-05,
        "epoch": 0.83
    },
    {
        "loss": 0.4774,
        "grad_norm": 0.012304052710533142,
        "learning_rate": 7.144896502498216e-05,
        "epoch": 0.86
    },
    {
        "loss": 0.4599,
        "grad_norm": 0.012862036935985088,
        "learning_rate": 7.073518915060672e-05,
        "epoch": 0.88
    },
    {
        "loss": 0.4657,
        "grad_norm": 0.011742646805942059,
        "learning_rate": 7.002141327623126e-05,
        "epoch": 0.9
    },
    {
        "loss": 0.4739,
        "grad_norm": 0.013051584362983704,
        "learning_rate": 6.930763740185582e-05,
        "epoch": 0.92
    },
    {
        "loss": 0.4716,
        "grad_norm": 0.010472019203007221,
        "learning_rate": 6.859386152748038e-05,
        "epoch": 0.94
    },
    {
        "loss": 0.4554,
        "grad_norm": 0.016577430069446564,
        "learning_rate": 6.788008565310494e-05,
        "epoch": 0.96
    },
    {
        "loss": 0.4624,
        "grad_norm": 0.013733156025409698,
        "learning_rate": 6.716630977872948e-05,
        "epoch": 0.98
    },
    {
        "loss": 0.4457,
        "grad_norm": 0.013386182487010956,
        "learning_rate": 6.645253390435403e-05,
        "epoch": 1.0
    },
    {
        "loss": 0.4853,
        "grad_norm": 0.015301055274903774,
        "learning_rate": 6.573875802997859e-05,
        "epoch": 1.03
    },
    {
        "loss": 0.447,
        "grad_norm": 0.014255933463573456,
        "learning_rate": 6.502498215560314e-05,
        "epoch": 1.05
    },
    {
        "loss": 0.4792,
        "grad_norm": 0.017970168963074684,
        "learning_rate": 6.43112062812277e-05,
        "epoch": 1.07
    },
    {
        "loss": 0.5037,
        "grad_norm": 0.012510024942457676,
        "learning_rate": 6.359743040685226e-05,
        "epoch": 1.09
    },
    {
        "loss": 0.4723,
        "grad_norm": 0.013119871728122234,
        "learning_rate": 6.288365453247682e-05,
        "epoch": 1.11
    },
    {
        "loss": 0.4639,
        "grad_norm": 0.014965353533625603,
        "learning_rate": 6.216987865810135e-05,
        "epoch": 1.13
    },
    {
        "loss": 0.4741,
        "grad_norm": 0.012171195819973946,
        "learning_rate": 6.145610278372591e-05,
        "epoch": 1.15
    },
    {
        "loss": 0.4062,
        "grad_norm": 0.013975385576486588,
        "learning_rate": 6.074232690935047e-05,
        "epoch": 1.18
    },
    {
        "loss": 0.4785,
        "grad_norm": 0.015025999397039413,
        "learning_rate": 6.002855103497502e-05,
        "epoch": 1.2
    },
    {
        "loss": 0.4592,
        "grad_norm": 0.011710869148373604,
        "learning_rate": 5.9314775160599576e-05,
        "epoch": 1.22
    },
    {
        "loss": 0.4833,
        "grad_norm": 0.013643398880958557,
        "learning_rate": 5.860099928622412e-05,
        "epoch": 1.24
    },
    {
        "loss": 0.4918,
        "grad_norm": 0.01583964191377163,
        "learning_rate": 5.7887223411848676e-05,
        "epoch": 1.26
    },
    {
        "loss": 0.4463,
        "grad_norm": 0.02092098630964756,
        "learning_rate": 5.7173447537473236e-05,
        "epoch": 1.28
    },
    {
        "loss": 0.4504,
        "grad_norm": 0.014863991178572178,
        "learning_rate": 5.645967166309779e-05,
        "epoch": 1.3
    },
    {
        "loss": 0.4522,
        "grad_norm": 0.013504229485988617,
        "learning_rate": 5.574589578872235e-05,
        "epoch": 1.33
    },
    {
        "loss": 0.4639,
        "grad_norm": 0.025567976757884026,
        "learning_rate": 5.50321199143469e-05,
        "epoch": 1.35
    },
    {
        "loss": 0.4385,
        "grad_norm": 0.015304495580494404,
        "learning_rate": 5.431834403997145e-05,
        "epoch": 1.37
    },
    {
        "loss": 0.4405,
        "grad_norm": 0.013778774067759514,
        "learning_rate": 5.3604568165596e-05,
        "epoch": 1.39
    },
    {
        "loss": 0.447,
        "grad_norm": 0.015464141964912415,
        "learning_rate": 5.2890792291220556e-05,
        "epoch": 1.41
    },
    {
        "loss": 0.4471,
        "grad_norm": 0.013181734830141068,
        "learning_rate": 5.2177016416845116e-05,
        "epoch": 1.43
    },
    {
        "loss": 0.436,
        "grad_norm": 0.01474951021373272,
        "learning_rate": 5.146324054246967e-05,
        "epoch": 1.45
    },
    {
        "loss": 0.4706,
        "grad_norm": 0.012968828901648521,
        "learning_rate": 5.0749464668094216e-05,
        "epoch": 1.48
    },
    {
        "loss": 0.4623,
        "grad_norm": 0.0176385585218668,
        "learning_rate": 5.003568879371877e-05,
        "epoch": 1.5
    },
    {
        "loss": 0.4549,
        "grad_norm": 0.016743453219532967,
        "learning_rate": 4.932191291934333e-05,
        "epoch": 1.52
    },
    {
        "loss": 0.4425,
        "grad_norm": 0.017469240352511406,
        "learning_rate": 4.860813704496788e-05,
        "epoch": 1.54
    },
    {
        "loss": 0.4544,
        "grad_norm": 0.01220061257481575,
        "learning_rate": 4.7894361170592436e-05,
        "epoch": 1.56
    },
    {
        "loss": 0.4637,
        "grad_norm": 0.01466267928481102,
        "learning_rate": 4.718058529621699e-05,
        "epoch": 1.58
    },
    {
        "loss": 0.4535,
        "grad_norm": 0.017540762200951576,
        "learning_rate": 4.646680942184154e-05,
        "epoch": 1.6
    },
    {
        "loss": 0.4377,
        "grad_norm": 0.01409119926393032,
        "learning_rate": 4.5753033547466095e-05,
        "epoch": 1.62
    },
    {
        "loss": 0.4499,
        "grad_norm": 0.0127590736374259,
        "learning_rate": 4.503925767309065e-05,
        "epoch": 1.65
    },
    {
        "loss": 0.4421,
        "grad_norm": 0.014571811072528362,
        "learning_rate": 4.432548179871521e-05,
        "epoch": 1.67
    },
    {
        "loss": 0.4406,
        "grad_norm": 0.01363078597933054,
        "learning_rate": 4.3611705924339755e-05,
        "epoch": 1.69
    },
    {
        "loss": 0.4649,
        "grad_norm": 0.015991106629371643,
        "learning_rate": 4.2897930049964315e-05,
        "epoch": 1.71
    },
    {
        "loss": 0.4632,
        "grad_norm": 0.015077629126608372,
        "learning_rate": 4.218415417558887e-05,
        "epoch": 1.73
    },
    {
        "loss": 0.4401,
        "grad_norm": 0.01516221184283495,
        "learning_rate": 4.147037830121342e-05,
        "epoch": 1.75
    },
    {
        "loss": 0.4437,
        "grad_norm": 0.014147232286632061,
        "learning_rate": 4.0756602426837975e-05,
        "epoch": 1.77
    },
    {
        "loss": 0.4612,
        "grad_norm": 0.012104008346796036,
        "learning_rate": 4.004282655246253e-05,
        "epoch": 1.8
    },
    {
        "loss": 0.4202,
        "grad_norm": 0.01201730314642191,
        "learning_rate": 3.932905067808708e-05,
        "epoch": 1.82
    },
    {
        "loss": 0.4469,
        "grad_norm": 0.014101716689765453,
        "learning_rate": 3.8615274803711635e-05,
        "epoch": 1.84
    },
    {
        "loss": 0.4232,
        "grad_norm": 0.0162983201444149,
        "learning_rate": 3.790149892933619e-05,
        "epoch": 1.86
    },
    {
        "loss": 0.4708,
        "grad_norm": 0.016250072047114372,
        "learning_rate": 3.718772305496074e-05,
        "epoch": 1.88
    },
    {
        "loss": 0.471,
        "grad_norm": 0.014017606154084206,
        "learning_rate": 3.64739471805853e-05,
        "epoch": 1.9
    },
    {
        "loss": 0.4478,
        "grad_norm": 0.01705167442560196,
        "learning_rate": 3.576017130620985e-05,
        "epoch": 1.92
    },
    {
        "loss": 0.4498,
        "grad_norm": 0.015467364341020584,
        "learning_rate": 3.504639543183441e-05,
        "epoch": 1.95
    },
    {
        "loss": 0.4368,
        "grad_norm": 0.01364108081907034,
        "learning_rate": 3.433261955745896e-05,
        "epoch": 1.97
    },
    {
        "loss": 0.4593,
        "grad_norm": 0.01720934361219406,
        "learning_rate": 3.3618843683083515e-05,
        "epoch": 1.99
    },
    {
        "loss": 0.4195,
        "grad_norm": 0.013959265314042568,
        "learning_rate": 3.290506780870807e-05,
        "epoch": 2.01
    },
    {
        "loss": 0.4584,
        "grad_norm": 0.02058659866452217,
        "learning_rate": 3.219129193433262e-05,
        "epoch": 2.03
    },
    {
        "loss": 0.4664,
        "grad_norm": 0.013781256042420864,
        "learning_rate": 3.1477516059957175e-05,
        "epoch": 2.05
    },
    {
        "loss": 0.4567,
        "grad_norm": 0.013989830389618874,
        "learning_rate": 3.076374018558173e-05,
        "epoch": 2.07
    },
    {
        "loss": 0.4486,
        "grad_norm": 0.013968333601951599,
        "learning_rate": 3.004996431120628e-05,
        "epoch": 2.09
    },
    {
        "loss": 0.4714,
        "grad_norm": 0.015266923233866692,
        "learning_rate": 2.9336188436830835e-05,
        "epoch": 2.12
    },
    {
        "loss": 0.4355,
        "grad_norm": 0.016313061118125916,
        "learning_rate": 2.862241256245539e-05,
        "epoch": 2.14
    },
    {
        "loss": 0.4193,
        "grad_norm": 0.01318948995321989,
        "learning_rate": 2.790863668807994e-05,
        "epoch": 2.16
    },
    {
        "loss": 0.4745,
        "grad_norm": 0.01224754098802805,
        "learning_rate": 2.7194860813704498e-05,
        "epoch": 2.18
    },
    {
        "loss": 0.4734,
        "grad_norm": 0.013648295775055885,
        "learning_rate": 2.6481084939329055e-05,
        "epoch": 2.2
    },
    {
        "loss": 0.464,
        "grad_norm": 0.01313064806163311,
        "learning_rate": 2.5767309064953605e-05,
        "epoch": 2.22
    },
    {
        "loss": 0.4612,
        "grad_norm": 0.015670467168092728,
        "learning_rate": 2.505353319057816e-05,
        "epoch": 2.24
    },
    {
        "loss": 0.4416,
        "grad_norm": 0.01544684637337923,
        "learning_rate": 2.4339757316202715e-05,
        "epoch": 2.27
    },
    {
        "loss": 0.4264,
        "grad_norm": 0.01904606632888317,
        "learning_rate": 2.3625981441827268e-05,
        "epoch": 2.29
    },
    {
        "loss": 0.4326,
        "grad_norm": 0.016246439889073372,
        "learning_rate": 2.291220556745182e-05,
        "epoch": 2.31
    },
    {
        "loss": 0.4574,
        "grad_norm": 0.01564897783100605,
        "learning_rate": 2.2198429693076374e-05,
        "epoch": 2.33
    },
    {
        "loss": 0.4532,
        "grad_norm": 0.01591533236205578,
        "learning_rate": 2.1484653818700928e-05,
        "epoch": 2.35
    },
    {
        "loss": 0.4702,
        "grad_norm": 0.015244078822433949,
        "learning_rate": 2.0770877944325484e-05,
        "epoch": 2.37
    },
    {
        "loss": 0.4541,
        "grad_norm": 0.013423527590930462,
        "learning_rate": 2.0057102069950038e-05,
        "epoch": 2.39
    },
    {
        "loss": 0.4317,
        "grad_norm": 0.015601588413119316,
        "learning_rate": 1.934332619557459e-05,
        "epoch": 2.42
    },
    {
        "loss": 0.4423,
        "grad_norm": 0.014454818330705166,
        "learning_rate": 1.8629550321199144e-05,
        "epoch": 2.44
    },
    {
        "loss": 0.4393,
        "grad_norm": 0.013548099435865879,
        "learning_rate": 1.79157744468237e-05,
        "epoch": 2.46
    },
    {
        "loss": 0.4428,
        "grad_norm": 0.01586025021970272,
        "learning_rate": 1.720199857244825e-05,
        "epoch": 2.48
    },
    {
        "loss": 0.4441,
        "grad_norm": 0.016216259449720383,
        "learning_rate": 1.6488222698072804e-05,
        "epoch": 2.5
    },
    {
        "loss": 0.4407,
        "grad_norm": 0.01528253871947527,
        "learning_rate": 1.5774446823697357e-05,
        "epoch": 2.52
    },
    {
        "loss": 0.4604,
        "grad_norm": 0.01470615342259407,
        "learning_rate": 1.5060670949321914e-05,
        "epoch": 2.54
    },
    {
        "loss": 0.4329,
        "grad_norm": 0.016974911093711853,
        "learning_rate": 1.4346895074946467e-05,
        "epoch": 2.57
    },
    {
        "loss": 0.447,
        "grad_norm": 0.017603544518351555,
        "learning_rate": 1.363311920057102e-05,
        "epoch": 2.59
    },
    {
        "loss": 0.443,
        "grad_norm": 0.010990536771714687,
        "learning_rate": 1.2919343326195577e-05,
        "epoch": 2.61
    },
    {
        "loss": 0.4451,
        "grad_norm": 0.012337367050349712,
        "learning_rate": 1.2205567451820129e-05,
        "epoch": 2.63
    },
    {
        "loss": 0.4353,
        "grad_norm": 0.014783690683543682,
        "learning_rate": 1.1491791577444682e-05,
        "epoch": 2.65
    },
    {
        "loss": 0.4265,
        "grad_norm": 0.013035569339990616,
        "learning_rate": 1.0778015703069237e-05,
        "epoch": 2.67
    },
    {
        "loss": 0.4396,
        "grad_norm": 0.018375642597675323,
        "learning_rate": 1.006423982869379e-05,
        "epoch": 2.69
    },
    {
        "loss": 0.457,
        "grad_norm": 0.015974221751093864,
        "learning_rate": 9.350463954318345e-06,
        "epoch": 2.71
    },
    {
        "loss": 0.4471,
        "grad_norm": 0.01842857524752617,
        "learning_rate": 8.636688079942897e-06,
        "epoch": 2.74
    },
    {
        "loss": 0.4552,
        "grad_norm": 0.013989556580781937,
        "learning_rate": 7.922912205567452e-06,
        "epoch": 2.76
    },
    {
        "loss": 0.4372,
        "grad_norm": 0.015954675152897835,
        "learning_rate": 7.209136331192005e-06,
        "epoch": 2.78
    },
    {
        "loss": 0.4452,
        "grad_norm": 0.015916375443339348,
        "learning_rate": 6.49536045681656e-06,
        "epoch": 2.8
    },
    {
        "loss": 0.4412,
        "grad_norm": 0.014643321745097637,
        "learning_rate": 5.781584582441114e-06,
        "epoch": 2.82
    },
    {
        "loss": 0.4308,
        "grad_norm": 0.015448952093720436,
        "learning_rate": 5.067808708065668e-06,
        "epoch": 2.84
    },
    {
        "loss": 0.4815,
        "grad_norm": 0.01559071522206068,
        "learning_rate": 4.354032833690221e-06,
        "epoch": 2.86
    },
    {
        "loss": 0.4347,
        "grad_norm": 0.014475065283477306,
        "learning_rate": 3.640256959314775e-06,
        "epoch": 2.89
    },
    {
        "loss": 0.429,
        "grad_norm": 0.014156943187117577,
        "learning_rate": 2.9264810849393293e-06,
        "epoch": 2.91
    },
    {
        "loss": 0.4279,
        "grad_norm": 0.012954546138644218,
        "learning_rate": 2.212705210563883e-06,
        "epoch": 2.93
    },
    {
        "loss": 0.4348,
        "grad_norm": 0.015776081010699272,
        "learning_rate": 1.498929336188437e-06,
        "epoch": 2.95
    },
    {
        "loss": 0.4325,
        "grad_norm": 0.01315250527113676,
        "learning_rate": 7.851534618129908e-07,
        "epoch": 2.97
    },
    {
        "loss": 0.4156,
        "grad_norm": 0.016665339469909668,
        "learning_rate": 7.137758743754461e-08,
        "epoch": 2.99
    }
]